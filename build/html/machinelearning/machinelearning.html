

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>算法 &mdash; Data Science 1.0 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="机器学习概览" href="machinelearning1.html" />
    <link rel="prev" title="机器学习" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Data Science
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README1.html">Data Science数据科学路线图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/index.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../R/index.html">R</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">机器学习</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">算法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#header-n4">机器学习算法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#header-n6">监督学习算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="#header-n196">非监督学习算法</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="machinelearning1.html">机器学习概览</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-lm.html">样例 - 回归</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-bayesian.html">样例 - 贝叶斯</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-tfidf.html">样例 - TFIDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-knn.html">样例 - k-NN k近邻</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-classification_tree.html">样例 - 分类树、回归树</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-glm.html">样例 - 逻辑回归</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-arcf.html">样例 - 关联规则与协同过滤</a></li>
<li class="toctree-l2"><a class="reference internal" href="evaluationpredictiveperformance.html">机器学习评估预测性能</a></li>
<li class="toctree-l2"><a class="reference internal" href="oracleml4python.html">Oracle机器学习 for Python</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../businessanalysis/index.html">Business Analysis 业务分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../managementmodel/index.html">管理模型</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Data Science</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">机器学习</a> &raquo;</li>
        
      <li>算法</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/machinelearning/machinelearning.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="header-n2">
<span id="id1"></span><h1>算法<a class="headerlink" href="#header-n2" title="永久链接至标题">¶</a></h1>
<p>机器学习常用算法数学公式</p>
<div class="section" id="header-n4">
<span id="id2"></span><h2>机器学习算法<a class="headerlink" href="#header-n4" title="永久链接至标题">¶</a></h2>
<div class="section" id="header-n6">
<span id="id3"></span><h3>监督学习算法<a class="headerlink" href="#header-n6" title="永久链接至标题">¶</a></h3>
<div class="section" id="header-n7">
<span id="id4"></span><h4>一、朴素贝叶斯<a class="headerlink" href="#header-n7" title="永久链接至标题">¶</a></h4>
<blockquote>
<div><p>请以<strong>嫁与不嫁高富帅矮矬穷</strong>的分类做理解</p>
<p>假设：每对特征之间相互<strong>独立</strong>，
很多情况下，朴素贝叶斯工作情况良好，特别是文本分类、文档分类、语言主题分类、垃圾邮件过滤</p>
</div></blockquote>
<p>给定一个类别 <span class="math notranslate nohighlight">\(y\)</span> 和一个从 <span class="math notranslate nohighlight">\(x_1\)</span>到 <span class="math notranslate nohighlight">\(x_n\)</span>
的相关的特征向量， 贝叶斯定理阐述了以下关系，方程式如下：</p>
<div class="math notranslate nohighlight">
\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)}{P(x_1, \dots, x_n)}  = \frac{P(y) P(x_1  \mid y) \dots P(x_n \mid y)}{P(x_1) \dots P(x_n)}\]</div>
<p>关系简化为如下：</p>
<div class="math notranslate nohighlight">
\[P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)}{P(x_1, \dots, x_n)}]\]</div>
<p>在如上公式分类规则中，给定的如下分母<span class="math notranslate nohighlight">\(P(x_1, \dots , x_n) = P(x_1) \dots P(x_n)\)</span>
的<strong>分类</strong>算法中，</p>
<div class="math notranslate nohighlight">
\[{P(x_1, \dots , x_n)} = P(x_1) \dots P(x_n)\]</div>
<p>这是一个 <strong>常量</strong>
，在类别对比中，分母相同，所以可以直接去掉分母，只比较分子，公式<strong>简化为</strong>如下分类规则：</p>
<div class="math notranslate nohighlight">
\[P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)\]</div>
<div class="math notranslate nohighlight">
\[\Downarrow\]</div>
<div class="math notranslate nohighlight">
\[\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y),\]</div>
<div class="section" id="header-n21">
<span id="id5"></span><h5>1.1 高斯朴素贝叶斯<a class="headerlink" href="#header-n21" title="永久链接至标题">¶</a></h5>
<p>GuassianNB
实现了运用分类的高斯朴素贝叶斯算法，特征的可能性（即概率）假设为高斯分布：</p>
<div class="math notranslate nohighlight">
\[P(x_i \mid y) = \frac{1}{\sqrt{2 \pi \sigma_y^2}} exp(- \frac {(x_i - \mu_y)^2}{2 \sigma_y^2})\]</div>
<ul>
<li><p>说明：参数<span class="math notranslate nohighlight">\(\mu_y\)</span>与<span class="math notranslate nohighlight">\(\sigma_y\)</span>
使用<strong>最大似然法估计</strong></p></li>
<li><p>代码参考：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of mislabeled points out of a total </span><span class="si">%d</span><span class="s2"> points : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">mislabeled</span> <span class="n">points</span> <span class="n">out</span> <span class="n">of</span> <span class="n">a</span> <span class="n">total</span> <span class="mi">150</span> <span class="n">points</span> <span class="p">:</span> <span class="mi">6</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="header-n31">
<span id="id6"></span><h5>1.2 多项式分布朴素贝叶斯<a class="headerlink" href="#header-n31" title="永久链接至标题">¶</a></h5>
<p>MultinomialNB 实现了服从多项分布数据的朴素贝叶斯算法，适用于文本分类，
与TF-IDF 同属于适用文本分类的<strong>两大经典算法</strong></p>
<ul class="simple">
<li><p>说明：文本分类表现良好</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n38">
<span id="id7"></span><h5>1.3 伯努利朴素贝叶斯<a class="headerlink" href="#header-n38" title="永久链接至标题">¶</a></h5>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n44">
<span id="id8"></span><h5>1.4 基于外存的朴素贝叶斯模型拟合<a class="headerlink" href="#header-n44" title="永久链接至标题">¶</a></h5>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
</div>
<div class="section" id="header-n50">
<span id="id9"></span><h4>二、广义线性模型<a class="headerlink" href="#header-n50" title="永久链接至标题">¶</a></h4>
<p>目标值 <span class="math notranslate nohighlight">\(y\)</span> 是输入变量 <span class="math notranslate nohighlight">\(x\)</span> 的线性组合。定义向量
:math:` (w_1, dots , w_p)`代表系数coef_，<span class="math notranslate nohighlight">\(w_0\)</span>
代表截距intercept_，数学概念表示为：</p>
<div class="math notranslate nohighlight">
\[\hat y (w,x) = w_0 + w_1 x_1 + \dots + w_p x_p\]</div>
<ul class="simple">
<li></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n58">
<span id="id10"></span><h4>三、线性判别分析与二次线性判别分析<a class="headerlink" href="#header-n58" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n64">
<span id="id11"></span><h4>四、支持向量机<a class="headerlink" href="#header-n64" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="knn">
<span id="header-n70"></span><h4>五、最近邻KNN<a class="headerlink" href="#knn" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n78">
<span id="id12"></span><h4>六、决策树<a class="headerlink" href="#header-n78" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n85">
<span id="id13"></span><h4>七、集成方法<a class="headerlink" href="#header-n85" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="tf-idf">
<span id="header-n92"></span><h4>八、TF-IDF（单文本词频-逆文档频率）<a class="headerlink" href="#tf-idf" title="永久链接至标题">¶</a></h4>
<ul>
<li><p>说明：TF：Term Frequency - IDF：Inverse Document Frequency
搜索关键词权重的科学度量、是对搜索关键词的重要性的度量，具备很强的理论依据</p></li>
<li><p>用途：TF-IDF是信息检索中最重要的发明，在搜索、文献分类和其他领域有广泛的应用</p></li>
<li><p>度量网页和查询的相关性的原理：</p>
<ol class="arabic">
<li><p>如果一个查询（贝叶斯算法的用途）包含<span class="math notranslate nohighlight">\(N\)</span>个关键词<span class="math notranslate nohighlight">\(w_1,w2,\dots,w_n\)</span>，他们在一个特定网页中的词频分别是：<span class="math notranslate nohighlight">\(TF_1,TF_2,\dots,TF_N \)</span>。比如某网页上一共1000个词，“贝叶斯”、“算法”、“的”、“用途”分别出现了3次、10次、20次、5次，那么他们的词频分别是：0.003、0.01、0.02、0.005，其和
<span class="math notranslate nohighlight">\(0.003 + 0.01 + 0.02 + 0.005 = 0.038\)</span>
就是“贝叶斯算法的用途”的“单文本词频”</p></li>
<li><p>上面词语中”的”是停用词，权重为零</p></li>
<li><p>假定关键词<span class="math notranslate nohighlight">\(w\)</span>在<span class="math notranslate nohighlight">\(D_w\)</span>个网页中出现过，那么<span class="math notranslate nohighlight">\(D_w\)</span>越大，w的权重就越小，<span class="math notranslate nohighlight">\(D_w\)</span>越小，w权重越大，如上面“的”在每个网页都有，所以权重就最小为0。<strong>逆文本频率IDF</strong>公式为<span class="math notranslate nohighlight">\(log (\frac {D} {D_w})\)</span>，其中<span class="math notranslate nohighlight">\(D\)</span>是总网页数目，<span class="math notranslate nohighlight">\(D_w\)</span>是出现关键词的网页数目</p></li>
<li><p>短语相关性的计算公式就由词频简单求和变成了加权求和，公式如下</p>
<div class="math notranslate nohighlight">
\[TF_1 \cdot IDF_1 + TF_2 \cdot IDF_2 + \cdots + TF_N \cdot IDF_N\]</div>
</li>
</ol>
<ol class="arabic">
<li><p>共有10亿个网页<span class="math notranslate nohighlight">\(D=10亿\)</span>，如“的”字，在10亿个网页中都出现过，就是<span class="math notranslate nohighlight">\(D_w=10亿\)</span>，所以“的”字权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w})=log( \frac {D=10亿}{D_w=十亿}) = log(1) = 0\)</span>，如“贝叶斯”在100万个网页中出现，“贝叶斯”的权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w}) = log(\frac {D=10亿}{D_w=100万})=log(1000)=9.966\)</span>；如“算法”在250万个网页中出现，“算法”的权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w}) = log(\frac {D=10亿}{D_w=250万})=log(400)=8.6438\)</span>；如“用途”在500万个网页中出现，“用途”的权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w}) = log(\frac {D=10亿}{D_w=500万})=log(200)=7.6438\)</span>；“的”为停用词，权重为0。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="nb">print</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><p>“贝叶斯算法的用途” 短语的TF-IDF详细计算结果如下：</p>
<div class="math notranslate nohighlight">
\[0.003 \cdot 9.966 + 0.01 \cdot 8.6438 + 0.02 \cdot 0 + 0.005 \cdot 7.6438 = 0.154555\]</div>
</li>
<li><p>结合网页排名（PageRank）算法，给定一个查询，搜索有关网页的综合排名大致由<strong>相关性和网页排名的乘积</strong>决定。</p></li>
</ol>
</li>
</ul>
</div>
</div>
<div class="section" id="header-n196">
<span id="id14"></span><h3>非监督学习算法<a class="headerlink" href="#header-n196" title="永久链接至标题">¶</a></h3>
<div class="section" id="header-n100">
<span id="id15"></span><h4>一、高斯混合模型<a class="headerlink" href="#header-n100" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n106">
<span id="id16"></span><h4>二、聚类<a class="headerlink" href="#header-n106" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="machinelearning1.html" class="btn btn-neutral float-right" title="机器学习概览" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="机器学习" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; 版权所有 2019, Shaofei Wang

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>