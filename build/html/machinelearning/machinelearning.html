

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>算法 &mdash; Data Science 1.0 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="机器学习概览" href="machinelearning1.html" />
    <link rel="prev" title="机器学习" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Data Science
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README1.html">Data Science数据科学路线图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/index.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../R/index.html">R</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">机器学习</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">算法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#header-n4">机器学习算法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#header-n6">监督学习算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="#header-n123">非监督学习算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#python-r">Python/R算法</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="machinelearning1.html">机器学习概览</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-lm.html">样例 - 回归</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-bayesian.html">样例 - 贝叶斯</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-tfidf.html">样例 - TFIDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-knn.html">样例 - k-NN k近邻</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-classification_tree.html">样例 - 分类树、回归树</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-glm.html">样例 - 逻辑回归</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-arcf.html">样例 - 关联规则与协同过滤</a></li>
<li class="toctree-l2"><a class="reference internal" href="evaluationpredictiveperformance.html">机器学习评估预测性能</a></li>
<li class="toctree-l2"><a class="reference internal" href="oracleml4python.html">Oracle机器学习 for Python</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../businessanalysis/index.html">Business Analysis 业务分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../managementmodel/index.html">管理模型</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Data Science</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">机器学习</a> &raquo;</li>
        
      <li>算法</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/machinelearning/machinelearning.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="header-n2">
<span id="id1"></span><h1>算法<a class="headerlink" href="#header-n2" title="永久链接至标题">¶</a></h1>
<p>机器学习常用算法数学公式</p>
<div class="section" id="header-n4">
<span id="id2"></span><h2>机器学习算法<a class="headerlink" href="#header-n4" title="永久链接至标题">¶</a></h2>
<div class="section" id="header-n6">
<span id="id3"></span><h3>监督学习算法<a class="headerlink" href="#header-n6" title="永久链接至标题">¶</a></h3>
<div class="section" id="header-n7">
<span id="id4"></span><h4>一、朴素贝叶斯<a class="headerlink" href="#header-n7" title="永久链接至标题">¶</a></h4>
<blockquote>
<div><p>请以<strong>嫁与不嫁高富帅矮矬穷或者西瓜书</strong>的分类做理解</p>
<p>假设：每对特征之间相互<strong>独立</strong>，
很多情况下，朴素贝叶斯工作情况良好，特别是文本分类、文档分类、语言主题分类、垃圾邮件过滤</p>
</div></blockquote>
<p>给定一个类别 <span class="math notranslate nohighlight">\(y\)</span> 和一个从 <span class="math notranslate nohighlight">\(x_1\)</span>到 <span class="math notranslate nohighlight">\(x_n\)</span>
的相关的特征向量， 贝叶斯定理阐述了以下关系，方程式如下：</p>
<div class="math notranslate nohighlight">
\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)}{P(x_1, \dots, x_n)}  = \frac{P(y) P(x_1  \mid y) \dots P(x_n \mid y)}{P(x_1) \dots P(x_n)}\]</div>
<p><span class="math notranslate nohighlight">\(P(y)\)</span> 是类别的“先验”概率，<span class="math notranslate nohighlight">\(P(x \mid y)\)</span>
是特征<span class="math notranslate nohighlight">\(x\)</span>对于类别标记<span class="math notranslate nohighlight">\(y\)</span>的类条件概率，或称为“似然”(likelihood)；简化为如下：</p>
<div class="math notranslate nohighlight">
\[P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)}{P(x_1, \dots, x_n)}]\]</div>
<p>在如上公式分类规则中，给定的如下分母<span class="math notranslate nohighlight">\(P(x_1, \dots , x_n) = P(x_1) \dots P(x_n)\)</span>
的<strong>分类</strong>算法中，</p>
<div class="math notranslate nohighlight">
\[{P(x_1, \dots , x_n)} = P(x_1) \dots P(x_n)
\quad 对所有类标记相同\]</div>
<p>这是一个 <strong>常量</strong>
，在类别对比中，分母相同，所以可以直接去掉分母，只比较分子，公式<strong>简化为</strong>如下贝叶斯判定规则：</p>
<div class="math notranslate nohighlight">
\[P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)\]</div>
<div class="math notranslate nohighlight">
\[\Downarrow\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y),\\\quad 对于“连乘”，通常通过取对数的方式转成“连加”，避免数值下溢\end{aligned}\end{align} \]</div>
<p>朴素贝叶斯分类器的训练过程是基于训练集来估计类别先验概率<span class="math notranslate nohighlight">\(P(y)\)</span>，并为每个属性/特征<span class="math notranslate nohighlight">\(x_i\)</span>估计条件概率<span class="math notranslate nohighlight">\(P(x_i \mid y)\)</span></p>
<div class="section" id="header-n22">
<span id="id5"></span><h5>1.1 高斯朴素贝叶斯<a class="headerlink" href="#header-n22" title="永久链接至标题">¶</a></h5>
<p>GuassianNB
实现了运用分类的高斯朴素贝叶斯算法，特征的可能性（即概率）假设为高斯分布：</p>
<div class="math notranslate nohighlight">
\[P(x_i \mid y) = \frac{1}{\sqrt{2 \pi \sigma_y^2}} exp(- \frac {(x_i - \mu_y)^2}{2 \sigma_y^2})\]</div>
<ul class="simple">
<li><p>说明：对连续属性而言，高斯模型假设特征符合正态分布，根据样本计算出均值和方差，就是概率密度函数等式右边其参数为<span class="math notranslate nohighlight">\(\mu_y 均值\)</span>与<span class="math notranslate nohighlight">\(\sigma_y 方差\)</span></p></li>
<li><p>用途：处理连续型的特征变量，如身高&lt;=160cm是1，160-170cm是2，&gt;170cm是3，可以将连续变量身高转换为离散变量：3个特征f1、f2、f3，但这些方式不够细腻。故引入高斯模型，可以很好地计算男、女身高、体重、脚掌的均值与方差，这样来计算性别。</p></li>
</ul>
</div>
<div class="section" id="header-n32">
<span id="id6"></span><h5>1.2 多项式分布朴素贝叶斯<a class="headerlink" href="#header-n32" title="永久链接至标题">¶</a></h5>
<p>MultinomialNB 实现了服从多项分布数据的朴素贝叶斯算法（MNB）， 与TF-IDF
同属于适用文本分类的<strong>两大经典算法</strong></p>
<ul>
<li><p>说明：对<strong>离散</strong>属性而言，对每一个类别<span class="math notranslate nohighlight">\(y\)</span>，<span class="math notranslate nohighlight">\(n\)</span>是特征数（在文本分类中是词汇量vocabulary），样本中特征<span class="math notranslate nohighlight">\(x_i\)</span>属于类别<span class="math notranslate nohighlight">\(y\)</span>的概率<span class="math notranslate nohighlight">\(P(x_i \mid y)\)</span>可估计为：</p>
<div class="math notranslate nohighlight">
\[P(x_i \mid y) = \frac {|D_{y,xi}|}{|D_y|}\]</div>
<div class="math notranslate nohighlight">
\[\Downarrow\]</div>
<p>为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，在估计概率值时通常要进行“平滑(smoothing)”，常用拉普拉斯平滑(Lapalce
smoothing <span class="math notranslate nohighlight">\(\alpha = 1\)</span>)或Lidstone平滑(Lidstone smoothing
<span class="math notranslate nohighlight">\(\alpha &lt; 1\)</span>)
，<span class="math notranslate nohighlight">\(N\)</span>表示训练集<span class="math notranslate nohighlight">\(D\)</span>中可能的类别数，<span class="math notranslate nohighlight">\(|D_y|\)</span>是类别中所有的特征的总计数，<span class="math notranslate nohighlight">\(|D_{y,x_1}|\)</span>是特征在训练集的样本中出现的次数，公式(8)修正为如下：</p>
<div class="math notranslate nohighlight">
\[\hat P(x_i \mid y) = \frac {|D_{y,xi}| + \alpha}{|D_y| + \alpha N}\]</div>
</li>
<li><p>用途：本算法在文本分类表现良好</p></li>
</ul>
</div>
<div class="section" id="header-n43">
<span id="id7"></span><h5>1.3 伯努利朴素贝叶斯<a class="headerlink" href="#header-n43" title="永久链接至标题">¶</a></h5>
<ul>
<li><p>说明：BernoulliNB实现了用于多重伯努利分布数据的朴素贝叶斯训练和分类算法，即有多个特征，但每个特征都假设是一个二元变量(Bernoulli，Boolean)，要求样本特征以二元值特征向量表示：</p>
<div class="math notranslate nohighlight">
\[P(x_i \mid y) = P(i \mid y) x_i + (1- P(i \mid y))(1 - x_i)\]</div>
</li>
<li><p>用途：适合在短文本分类</p></li>
</ul>
</div>
<div class="section" id="header-n50">
<span id="id8"></span><h5>1.4 补充朴素贝叶斯<a class="headerlink" href="#header-n50" title="永久链接至标题">¶</a></h5>
<ul class="simple">
<li><p>说明：ComplementNB
实现了补充朴素贝叶斯（CNB）算法，是1.2的（MNB）的一种改进算法，CNB使用每个类的补集的统计量来计算模型的权重，CNB的参数估计比MNB的参数估计更稳定，比MNB表现的更好</p></li>
<li><p>用途：特别适用于不平衡数据集，解决了MMB中较长文档主导参数估计的趋势。</p></li>
</ul>
</div>
</div>
<div class="section" id="header-n56">
<span id="id9"></span><h4>二、线性回归模型<a class="headerlink" href="#header-n56" title="永久链接至标题">¶</a></h4>
<p>目标值 <span class="math notranslate nohighlight">\(y\)</span> 是输入变量 <span class="math notranslate nohighlight">\(x\)</span> 的线性组合。定义向量
:math:` (w_1, dots , w_p)`代表系数coef_，<span class="math notranslate nohighlight">\(w_0\)</span>
代表截距intercept_，数学概念表示为：</p>
<div class="math notranslate nohighlight">
\[\hat y (w,x) = w_0 + w_1 x_1 + \dots + w_p x_p\]</div>
<ul>
<li><p>说明：算法是拟合一个带有系数<span class="math notranslate nohighlight">\(w = (w_1, \cdots, w_p)\)</span>的线性模型，是的数据集实际<strong>观测数据</strong>与<strong>预测数据</strong>之间的残差平方和最小，数学概念表示为：</p>
<div class="math notranslate nohighlight">
\[\underset{w}{min\,} \mid \mid X_w - y \mid \mid^2\]</div>
</li>
<li><p>用途：各特征<span class="math notranslate nohighlight">\(x_1, \cdots, x_p\)</span>相互独立的情况下预测连续变量。</p></li>
<li></li>
</ul>
</div>
<div class="section" id="header-n68">
<span id="id10"></span><h4>三、线性判别分析与二次线性判别分析<a class="headerlink" href="#header-n68" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n74">
<span id="id11"></span><h4>四、支持向量机<a class="headerlink" href="#header-n74" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="kknn">
<span id="header-n80"></span><h4>五、k近邻KNN<a class="headerlink" href="#kknn" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>参考：[KNN最近邻算法]:<a class="reference external" href="https://theroadtodatascience.readthedocs.io/en/latest/machinelearning/ml-knn.html">https://theroadtodatascience.readthedocs.io/en/latest/machinelearning/ml-knn.html</a></p></li>
</ul>
</div>
<div class="section" id="header-n84">
<span id="id12"></span><h4>六、决策树<a class="headerlink" href="#header-n84" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li></li>
</ul>
</div>
<div class="section" id="header-n89">
<span id="id13"></span><h4>七、集成方法<a class="headerlink" href="#header-n89" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="tf-idf">
<span id="header-n96"></span><h4>八、TF-IDF（单文本词频-逆文档频率）<a class="headerlink" href="#tf-idf" title="永久链接至标题">¶</a></h4>
<ul>
<li><p>说明：TF：Term Frequency - IDF：Inverse Document Frequency
搜索关键词权重的科学度量、是对搜索关键词的重要性的度量，具备很强的理论依据</p></li>
<li><p>用途：TF-IDF是信息检索中最重要的发明，在搜索、文献分类和其他领域有广泛的应用</p></li>
<li><p>度量网页和查询的相关性的原理：</p>
<ol class="arabic">
<li><p>如果一个查询（贝叶斯算法的用途）包含<span class="math notranslate nohighlight">\(N\)</span>个关键词<span class="math notranslate nohighlight">\(w_1,w2,\dots,w_n\)</span>，他们在一个特定网页中的词频分别是：<span class="math notranslate nohighlight">\(TF_1,TF_2,\dots,TF_N \)</span>。比如某网页上一共1000个词，“贝叶斯”、“算法”、“的”、“用途”分别出现了3次、10次、20次、5次，那么他们的词频分别是：0.003、0.01、0.02、0.005，其和
<span class="math notranslate nohighlight">\(0.003 + 0.01 + 0.02 + 0.005 = 0.038\)</span>
就是“贝叶斯算法的用途”的“单文本词频”</p></li>
<li><p>上面词语中”的”是停用词，权重为零</p></li>
<li><p>假定关键词<span class="math notranslate nohighlight">\(w\)</span>在<span class="math notranslate nohighlight">\(D_w\)</span>个网页中出现过，那么<span class="math notranslate nohighlight">\(D_w\)</span>越大，w的权重就越小，<span class="math notranslate nohighlight">\(D_w\)</span>越小，w权重越大，如上面“的”在每个网页都有，所以权重就最小为0。<strong>逆文本频率IDF</strong>公式为<span class="math notranslate nohighlight">\(log (\frac {D} {D_w})\)</span>，其中<span class="math notranslate nohighlight">\(D\)</span>是总网页数目，<span class="math notranslate nohighlight">\(D_w\)</span>是出现关键词的网页数目</p></li>
<li><p>短语相关性的计算公式就由词频简单求和变成了加权求和，公式如下</p>
<div class="math notranslate nohighlight">
\[TF_1 \cdot IDF_1 + TF_2 \cdot IDF_2 + \cdots + TF_N \cdot IDF_N\]</div>
</li>
<li><p>共有10亿个网页<span class="math notranslate nohighlight">\(D=10亿\)</span>，如“的”字，在10亿个网页中都出现过，就是<span class="math notranslate nohighlight">\(D_w=10亿\)</span>，所以“的”字权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w})=log( \frac {D=10亿}{D_w=十亿}) = log(1) = 0\)</span>，如“贝叶斯”在100万个网页中出现，“贝叶斯”的权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w}) = log(\frac {D=10亿}{D_w=100万})=log(1000)=9.966\)</span>；如“算法”在250万个网页中出现，“算法”的权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w}) = log(\frac {D=10亿}{D_w=250万})=log(400)=8.6438\)</span>；如“用途”在500万个网页中出现，“用途”的权重就是<span class="math notranslate nohighlight">\(log( \frac {D}{D_w}) = log(\frac {D=10亿}{D_w=500万})=log(200)=7.6438\)</span>；“的”为停用词，权重为0。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="nb">print</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><p>“贝叶斯算法的用途” 短语的TF-IDF详细计算结果如下：</p>
<div class="math notranslate nohighlight">
\[0.003 \cdot 9.966 + 0.01 \cdot 8.6438 + 0.02 \cdot 0 + 0.005 \cdot 7.6438 = 0.154555\]</div>
</li>
<li><p>结合网页排名（PageRank）算法，给定一个查询，搜索有关网页的综合排名大致由<strong>相关性和网页排名的乘积</strong>决定。</p></li>
</ol>
</li>
</ul>
</div>
</div>
<div class="section" id="header-n123">
<span id="id14"></span><h3>非监督学习算法<a class="headerlink" href="#header-n123" title="永久链接至标题">¶</a></h3>
<div class="section" id="header-n125">
<span id="id15"></span><h4>一、高斯混合模型<a class="headerlink" href="#header-n125" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
<div class="section" id="header-n131">
<span id="id16"></span><h4>二、聚类<a class="headerlink" href="#header-n131" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>说明</p></li>
<li><p>用途</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="python-r">
<span id="header-n140"></span><h2>Python/R算法<a class="headerlink" href="#python-r" title="永久链接至标题">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="machinelearning1.html" class="btn btn-neutral float-right" title="机器学习概览" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="机器学习" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; 版权所有 2019, Shaofei Wang

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>